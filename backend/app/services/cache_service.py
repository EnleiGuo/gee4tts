import asyncio
import json
import hashlib
import pickle
from typing import Optional, Any, Dict
import logging
from datetime import datetime, timedelta

# ä¸´æ—¶ç¦ç”¨ Redis ä»¥é¿å…å…¼å®¹æ€§é—®é¢˜
try:
    # import aioredis
    REDIS_AVAILABLE = False  # å¼ºåˆ¶ä½¿ç”¨å†…å­˜ç¼“å­˜
except ImportError:
    REDIS_AVAILABLE = False

from app.core.config import settings

logger = logging.getLogger(__name__)


class CacheService:
    """ç»Ÿä¸€ç¼“å­˜æœåŠ¡ï¼Œæ”¯æŒRediså’Œå†…å­˜ç¼“å­˜"""
    
    def __init__(self):
        self.redis_client = None
        self.memory_cache: Dict[str, Dict] = {}
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "sets": 0,
            "deletes": 0
        }
        
    async def initialize(self):
        """åˆå§‹åŒ–ç¼“å­˜æœåŠ¡"""
        if REDIS_AVAILABLE and settings.REDIS_URL:
            try:
                self.redis_client = aioredis.from_url(
                    settings.REDIS_URL,
                    encoding="utf-8",
                    decode_responses=True,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
                # æµ‹è¯•è¿æ¥
                await self.redis_client.ping()
                logger.info("âœ… Redisç¼“å­˜æœåŠ¡è¿æ¥æˆåŠŸ")
            except Exception as e:
                logger.warning(f"Redisè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜ç¼“å­˜: {str(e)}")
                self.redis_client = None
        else:
            logger.info("ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æœåŠ¡")
    
    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        try:
            if self.redis_client:
                # ä½¿ç”¨Redis
                cached_data = await self.redis_client.get(key)
                if cached_data:
                    self.cache_stats["hits"] += 1
                    return json.loads(cached_data)
            else:
                # ä½¿ç”¨å†…å­˜ç¼“å­˜
                cache_item = self.memory_cache.get(key)
                if cache_item and cache_item["expires_at"] > datetime.utcnow():
                    self.cache_stats["hits"] += 1
                    return cache_item["data"]
                elif cache_item:
                    # è¿‡æœŸåˆ é™¤
                    del self.memory_cache[key]
            
            self.cache_stats["misses"] += 1
            return None
            
        except Exception as e:
            logger.error(f"ç¼“å­˜è·å–å¤±è´¥ {key}: {str(e)}")
            self.cache_stats["misses"] += 1
            return None
    
    async def set(
        self, 
        key: str, 
        value: Any, 
        expire: Optional[int] = None
    ) -> bool:
        """è®¾ç½®ç¼“å­˜å€¼"""
        try:
            if self.redis_client:
                # ä½¿ç”¨Redis
                cached_data = json.dumps(value, ensure_ascii=False, default=str)
                if expire:
                    await self.redis_client.setex(key, expire, cached_data)
                else:
                    await self.redis_client.set(key, cached_data)
            else:
                # ä½¿ç”¨å†…å­˜ç¼“å­˜
                expires_at = datetime.utcnow() + timedelta(
                    seconds=expire or settings.CACHE_EXPIRE_SECONDS
                )
                self.memory_cache[key] = {
                    "data": value,
                    "expires_at": expires_at
                }
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                await self._cleanup_expired_memory_cache()
            
            self.cache_stats["sets"] += 1
            return True
            
        except Exception as e:
            logger.error(f"ç¼“å­˜è®¾ç½®å¤±è´¥ {key}: {str(e)}")
            return False
    
    async def delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        try:
            if self.redis_client:
                await self.redis_client.delete(key)
            else:
                self.memory_cache.pop(key, None)
            
            self.cache_stats["deletes"] += 1
            return True
            
        except Exception as e:
            logger.error(f"ç¼“å­˜åˆ é™¤å¤±è´¥ {key}: {str(e)}")
            return False
    
    async def clear_pattern(self, pattern: str) -> int:
        """æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜"""
        try:
            deleted_count = 0
            
            if self.redis_client:
                keys = await self.redis_client.keys(pattern)
                if keys:
                    deleted_count = await self.redis_client.delete(*keys)
            else:
                # å†…å­˜ç¼“å­˜æ¨¡å¼åŒ¹é…
                import fnmatch
                keys_to_delete = [
                    key for key in self.memory_cache.keys() 
                    if fnmatch.fnmatch(key, pattern)
                ]
                for key in keys_to_delete:
                    del self.memory_cache[key]
                deleted_count = len(keys_to_delete)
            
            logger.info(f"æ¸…ç†ç¼“å­˜æ¨¡å¼ {pattern}: åˆ é™¤{deleted_count}é¡¹")
            return deleted_count
            
        except Exception as e:
            logger.error(f"ç¼“å­˜æ¨¡å¼æ¸…ç†å¤±è´¥ {pattern}: {str(e)}")
            return 0
    
    def generate_cache_key(self, prefix: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # åˆ›å»ºç¨³å®šçš„é”®å€¼
        key_parts = [str(prefix)]
        for k, v in sorted(kwargs.items()):
            key_parts.append(f"{k}:{v}")
        
        key_string = "|".join(key_parts)
        key_hash = hashlib.md5(key_string.encode()).hexdigest()
        return f"{prefix}:{key_hash}"
    
    async def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.cache_stats.copy()
        
        if self.redis_client:
            try:
                info = await self.redis_client.info("memory")
                stats.update({
                    "type": "redis",
                    "redis_memory_used": info.get("used_memory_human", "unknown"),
                    "redis_keys": await self.redis_client.dbsize()
                })
            except:
                stats["type"] = "redis_error"
        else:
            stats.update({
                "type": "memory",
                "memory_keys": len(self.memory_cache),
                "memory_usage_mb": self._get_memory_cache_size()
            })
        
        # è®¡ç®—å‘½ä¸­ç‡
        total_requests = stats["hits"] + stats["misses"]
        stats["hit_rate"] = (
            stats["hits"] / total_requests if total_requests > 0 else 0
        )
        
        return stats
    
    async def _cleanup_expired_memory_cache(self):
        """æ¸…ç†è¿‡æœŸçš„å†…å­˜ç¼“å­˜"""
        now = datetime.utcnow()
        expired_keys = [
            key for key, item in self.memory_cache.items()
            if item["expires_at"] <= now
        ]
        
        for key in expired_keys:
            del self.memory_cache[key]
        
        if expired_keys:
            logger.debug(f"æ¸…ç†è¿‡æœŸç¼“å­˜: {len(expired_keys)}é¡¹")
    
    def _get_memory_cache_size(self) -> float:
        """ä¼°ç®—å†…å­˜ç¼“å­˜å¤§å°(MB)"""
        try:
            size_bytes = len(pickle.dumps(self.memory_cache))
            return round(size_bytes / 1024 / 1024, 2)
        except:
            return 0.0
    
    async def close(self):
        """å…³é—­ç¼“å­˜è¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("ğŸ”Œ Redisè¿æ¥å·²å…³é—­")


# å…¨å±€ç¼“å­˜å®ä¾‹
cache_service = CacheService()